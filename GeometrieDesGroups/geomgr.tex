\documentclass{amsart}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{bm}
\def\1{\bm{1}}
%%% Comment out to get rid of links at urls in the footnotes 
\usepackage[hyperfootnotes=false]{hyperref}



\usepackage{titlesec}
\titleformat{\section}{\normalfont\bf\large}{\thesection. }{0em}{}

\usepackage{manyfoot}
\DeclareNewFootnote{A}
\DeclareNewFootnote{E}[alph]

\usepackage{xcolor}
\long\def\gray#1{{\color{gray}{#1}}}
\long\def\blue#1{{\color{blue}{#1}}}
\long\def\red#1{{\color{red}{#1}}}

\usepackage{lpic}

% \let\d=\undefined
% \DeclareMathOperator{\d}{d}
\def\sltwo{\ensuremath{\mathrm{SL}(n,\mathbb{Z})}}


\newtheorem*{definition}{Definition}
\newtheorem*{theorem}{Theorem}


\begin{document}
\centerline{\bf A Bit of Geometric Group Theory}
\medskip
\centerline{by  Gilbert Levitt}

\bigskip
\centerline{
  \begin{lpic}[b(28mm),draft,clean]{Pix/escher-circle-limit-III(1)}
    \lbl[t]{28,-2;
      \parbox{0.8\textwidth}{
        \hfill Maurits Cornelis Escher, \textit{Circle Limit
          III}, Print, 1959\hfill\ 
        \vspace{1ex} \\
        \sf Discrete groups appear in every area of mathematics
        --- and even in Escher’s art.  Even if they are defined algebraically,
        we often understand them better by their action on
        geometric objects. More and more often, they are viewed as
        geometric entities in their own right. Their properties are
        especially striking when the curvature is negative.%
      }}
  \end{lpic}
}

\section{A Few Examples of Groups}
We consider a group $G$, generally non-commutative. We will write it
multiplicatively, with the neutral element denoted $\1_{G}$ or simply
$\1$. Groups that will interest us most are finitely generated
---that is, that is they can be generated by a finite number of
elements. Let’s take a look at a few examples.
\begin{itemize}
\item The \textit{free abelian group} $\mathbb{Z}^2$, or
  $\mathbb{Z} \times \mathbb{Z}$, or $\mathbb{Z} \oplus \mathbb{Z}$,
  is the set of pairs of integers $(m, n)$, with addition defined by
  $(m, n) + (m', n') = (m + m', n + n')$.  To write it
  multiplicatively, let $a = (1, 0)$, $b = (0, 1)$, and view
  $\mathbb{Z}^2$ as the set of elements $a^m b^n$, equipped with the
  multiplication rule
  $(a^m b^n)(a^{m'} b^{n'}) = a^{m + m'} b^{n + n'}$.  The neutral
  element $a^0 b^0$ is denoted $\1$, and the inverse of $a^m b^n$ is
  $a^{-m} b^{-n}$.
\item Let us consider the group $\mathrm{Aff}(\mathbb{R})$ acting on the real
  line $\mathbb{R}$ by homotheties and translations --- that is, the
  transformations of the form $x \mapsto a\cdot x + b$ with
  $a, b \in \mathbb{R}$ and $a \neq 0$, the product being given by
  composition $(f \circ g)(x) = f(g(x))$.

  This is a ``continuous'' group (a Lie group), but we can consider
  finitely generated subgroups, for example the group $G_1$ generated
  by $t : x \mapsto x + 1$ and $h : x \mapsto 2x$.
  One can deduce that $G_1$ is the set of transformations $\varphi_{mnp}$
  of the form $\varphi_{mnp}(x) = 2^m x + n 2^p$, with
  $m, n, p \in \mathbb{Z}$ (see box).

\item The group $\mathrm{GL}(n, \mathbb{R})$ of invertible (with
  determinant $\neq 0$)
  $n \times n$ matrices with real coefficients is also a Lie group.

  The matrices with integer entries do not form a subgroup, because
  the determinant appears in the denominator when computing the
  inverse of a matrix.
  However, \sltwo, the set of matrices with
  integer entries and determinant $1$, is a subgroup.

  We will consider the group $G_2 \subset \sltwo$
  generated by
  \[
    A=\begin{pmatrix}1&0\\2&1\end{pmatrix},\quad
    B=\begin{pmatrix}1&2\\0&1\end{pmatrix}
  \]
\end{itemize}

\section{Free Groups}

In a vector space $V$ over a field $K$, the \textit{vector subspace} generated
by vectors $\{v_1, \dots, v_k\}$ in $V$ is the set of all linear combinations
\[
  \sum_{i=1}^{k}\lambda_{i}v_{i},
\]
with $\lambda_{i}\in K$.  The elements $v_1, \dots, v_k$ are
\textit{linearly independent} if any two different linear combinations
represent different elements of $V$, or equivalently, if there is no
relation
\[
  \sum_{i=1}^{k}\lambda_{i}v_{i}=0
\]
with the $\lambda_i$ not all zero.
The subspace generated has then dimension $k$ and is isomorphic to $K^k$.

In a group $G$, the subgroup generated by ${g_1, \dots, g_k}$ is the
set of all elements of $G$ that can be written as a reduced word
$g_{i_{1}}^{n_{i}}\dots g_{i_{p}}^{n_{p}}$, where the $n_j$ are
nonzero integers and $i_j \neq i_{j+1}$.  For example, $a^2$,
$b^{-1}c$, and $c^{-3}a^3b^2acb^{-5}$ are reduced words in $a, b, c$.
Care must be taken not to forget the empty word, denoted $1$, which
represents the identity element $1_G$.  The length $|W|$ of a word $W$
is the total number of letters, taking exponents into account, for
example $|c^{-3}a^{3}b^{2}acb^{-5}|=15$.

We say that elements $g_1, \dots, g_k$ of $G$ are
\textit{independent}%
\footnoteE{Often in the literature by indpendence of the collection
  $g_1, \dots, g_k$ of elements of a group, another, in general
  strictly stronger, condition is meant, namely that no element is
  equal to a reduced word in other elements of the collection.}  (or
form a \textit{free family}) if two different reduced words always
represent two different elements of $G$, or equivalently, if there is
no nontrivial relation $g_{i_1}^{n_1} \cdots g_{i_p}^{n_p} = 1$. Thus,
the family ${g}$ (consisting of the single element $g$) is free if and
only if there is no nontrivial relation $g^n = 1$, that is, if $g$ has
infinite order.

In the examples above, the families ${a, b} \subset \mathbb{Z}^2$ and
${h, t} \subset G_1$ are not free, because of the relations $ab = ba$
and $hth^{-1} = t^2$.

We will, however, show --- using the so-called ping-pong technique ---
that the matrices $A$ and $B$ are independent in \sltwo.

To this end, let us make \sltwo{} act on
$P = \mathbb{R} \cup {\infty}$ (the real projective line) by
associating to the \sltwo-matrix
\[
  M = \begin{pmatrix} a & b \\ c & d \end{pmatrix}
\]
the \textit{homography} (or \textit{projective transformation})
\[
  h_M : x \mapsto \dfrac{a x + b}{c x + d}
\]
with the usual conventions, in particular $h_M(-d/c) = \infty$ and
$h_M(\infty) = a/c$ if $c \neq 0$. The definition is made so that
$h_{MN} = h_M h_N$ for all pairs of $\sltwo$-matrices $M$ and $N$.

Let $P_A = (-1, 1)$, and let $P_B$ be the complement of $[-1, 1]$ in
$P$. We have $h_A(x) = x + 2$, and therefore $h_A^n(P_A) \subset P_B$
for all $n \neq 0$. Similarly, $h_B(x) = x/(2x+1)$
and $h_B^n(P_B) \subset P_A$ for $n \neq
0$.%
\footnoteE{Note also, that the inclusions $h_A^n(P_A) \subset P_B$ and
  $h_B^n(P_B) \subset P_A$ are strict.}
Let's now play ping-pong with $P_A$ and $P_B$.

To show that $A$ and $B$ are independent, consider a nontrivial
reduced word, for example $W = B^2 A B^{-3} A^5$. Apply
$h_W = h_B^2 h_A h_B^{-3} h_A^5$ to $P_A$. The element $h_A^5$ sends
it into $P_B$, the element $h_B^{-3}$ sends it back into $P_A$, and so
on, and finally $h_W(P_A)$ is contained in $P_A$ but not equal to
it. This prevents $h_W$ from being the identity, and therefore $W$
from being equal to $1$ in $\mathrm{SL}(2, \mathbb{Z})$.

This reasoning applies to any word $W$ beginning with a power of $B$
and ending with a power of $A$. The other cases are treated similarly:
if $W$ begins and ends with a power of $A$, we have
$h_W \neq \mathrm{id}$ because $h_W(P_A) \subset P_B$; if $W$ ends
with a power of $B$, we apply $h_W$ to $P_B$.

Since $A$ and $B$ are independent, every element of $G_2$ can be
written uniquely as a reduced word in $A$ and $B$. At this point we
can forget that $A$ and $B$ are matrices and regard $G_2$ as the set
$F(A, B)$ of reduced words in two abstract symbols $A$ and
$B$. Multiplication consists of concatenation and reduction; for
example, $(B^2 A B^{-3} A^5)(A^{-5} B A^4) = B^2 A B^{-2} A^4$, and
the inverse of $B^2 A B^{-3} A^5$ is $A^{-5} B^3 A^{-1} B^{-2}$.

We say that $G_2$ is the free group of rank 2, often denoted
$F_2$. Similarly, we define $F_n$, the free group of rank $n$, for
$n > 2$.

Many groups contain subgroups which are free groups. For example, one
can show that two randomly chosen rotations of the sphere generate a
free group, as do the transformations $x \mapsto x + 1$ and
$x \mapsto x^3$ on $\mathbb{R}$.

The group $F_2$ contains arbitrarily large free families: it is easy
to see that the infinite family ${A^n B A^{-n}}_{n \in \mathbb{N}}$ is
free, because the $B$’s do not cancel when these elements are
multiplied. The free group of rank 2 therefore contains free groups of
any rank, and even groups that are not finitely generated. The
Nielsen–Schreier theorem guarantees that every subgroup of a free
group is free, that is, it is generated by a free family.

\section{Tits Alternative}

We have already noted that $G_1$ is not free, since its generators
satisfy $h t h^{-1} = t^2$. To find other relations, observe that in
$\mathrm{Aff}(\mathbb{R})$, and therefore in $G_1$, every commutator
$[g_1, g_2] := g_1 g_2 g_1^{-1} g_2^{-1}$ is a translation, and that
two translations commute. Therefore any two commutators commute,
$[g_1, g_2][g_3, g_4] = [g_3, g_4][g_1, g_2]$ for all
$g_1, g_2, g_3, g_4 \in G_1$. This ``universal'' relation expresses that
$G_1$ is \textit{metabelian}, or equivalently, \textit{solvable} of class 2.

More generally, we say that $G$ is solvable of class $\leq p$ if the
subgroup generated by all commutators $[g_1, g_2]$ is solvable of
class $\leq p - 1$, that is, if any $2p$ elements of $G$ satisfy a
certain identity built from iterated commutators. Solvable groups are
those that can be obtained by successive extensions from commutative
groups. The impossibility of solving algebraic equations of degree 5
by radicals is due to the non-solvability of the symmetric group $S_5$
This  subject of the \textit{Galois theory}.

It is easy to verify that, for any field $K$, the subgroup of
$\mathrm{GL}(n, K)$ consisting of invertible upper triangular matrices
is solvable (of class $n$). The famous Tits alternative (1972) states
that if a finitely generated group $G$ is linear --- that is, isomorphic
to a subgroup of some $\mathrm{GL}(n, K)$ --- then either $G$ contains a
subgroup isomorphic to $F_2$, or a subgroup of finite index in $G$
(see box) is solvable.

In other words, either $G$ contains arbitrarily large free families,
or (up to finite index) the elements of $G$ satisfy a universal
relation. The Tits alternative has been extended to other classes of groups; for
instance, Bestvina, Feighn, and Handel have recently proved it for
subgroups of the group $\mathrm{Out}(F_n)$ of automorphisms of a
finitely generated free group, modulo conjugation.


\section{Relations and Presentations}

If a group $G$ is not free, different reduced words may represent the
same element; we say that they are equivalent. The word problem
consists in deciding (algorithmically) whether two given words are
equivalent or not. In fact, it suffices to determine which words are
trivial, that is, which represent the neutral element $\1_G$.

This is easy in $\mathbb{Z}^2$, which is commutative. For instance, it
is immediately clear to us that
$a^{100} b^{100} a^{-100} b^{-100} = \1$. But a machine that could only
apply mechanically the basic relation $ab = ba$ (and, to be generous,
the relations $a^{\pm1} b^{\pm1} = b^{\pm1} a^{\pm1}$) would find it
tedious to show this equality: it would in fact have to move each of
the one hundred $a^{-1}$’s past each $b$, that is, about $10\,000$
operations for a word of length $400$. In general, the number of
operations required to show that a word of length $n$ is trivial is,
in the worst case, on the order of $n^2$ for large $n$. We say that
$\mathbb{Z}^2$ has a quadratic isoperimetric inequality.

The geometric interpretation is as follows (see Figure 1). Tile the
plane with a grid whose horizontal edges are oriented to the right and
labeled $a$, and whose vertical edges are oriented upward and labeled
$b$. Fix a vertex $E$ of this graph as the origin. A word in $a$ and
$b$ can then be represented as a path starting from $E$; for example,
$a^2 b^{-1} a^{-1} b^{-1}$ moves two units to the right, one down, one
to the left, and one down again.

\centerline{
  \begin{lpic}[draft,l(11mm),r(11mm),b(21mm),t(2mm),clean]{Pix/z2(0.4)}
    \lbl[b]{60,73;\color{blue}$a$}
    \lbl[b]{80,73;\color{blue}$a$}
    \lbl[l]{93,60;\color{blue}$b^{-1}$}
    \lbl[b]{80,53;\color{blue}$a^{-1}$}
    \lbl[l]{73,40;\color{blue}$b^{-1}$}
    \lbl[b]{60,33;\color{blue}$a^{-1}$}
    \lbl[l]{53,20;\color{blue}$b^{-1}$}
    \lbl[t]{43,9;\color{blue}$a^{-1}$}
    \lbl[r]{27,20;\color{blue}$b$}
    \lbl[b]{23,33;\color{blue}$a^{-1}$}
    \lbl[r]{7,40;\color{blue}$b$}
    \lbl[b]{40,73;\color{red}$a^{-1}$}
    \lbl[b]{20,73;\color{red}$a^{-1}$}
    \lbl[r]{9,60;\color{red}$b^{-1}$}
    \lbl[tW]{50,64;$E$}
    \lbl[lW]{16.5,50;$F$}
    
    \lbl[t]{50,-2;\parbox{0.5\textwidth}{
        \centerline{\bf Figure 1.}
        \raggedright The words
        \blue{$a^2 b^{-1} a^{-1} b^{-1} a^{-1} b^{-1} a^{-1} b a^{-1} b$} and
        \red{$a^{-2} b^{-1}$} represent the same element of $\mathbb{Z}^2$:
        the corresponding paths have the same endpoint $F$.}}
  \end{lpic}
}

We note that two words are equivalent if and only if their associated
paths have the same endpoint; for example,
$a^2 b^{-1} a^{-1} b^{-1} a^{-1} b^{-1} a^{-1} b a^{-1} b$ is
equivalent to $a^{-2} b^{-1}$. In particular, the vertices of the
graph correspond to the elements of $\mathbb{Z}^2$, and a word is
trivial if and only if the associated path is a loop (it closes back
at $E$). Thus, $a^{100} b^{100} a^{-100} b^{-100}$ represents the
boundary of a square of side $100$. Applying the relation
$a^{\pm1} b^{\pm1} = b^{\pm1} a^{\pm1}$ amounts to having the loop
cross one cell of the grid, and $10{,}000$ is simply the area of the
square.

The exponent $2$ obtained above is thus the one that expresses the
area of a square as a function of its side. We can see the analogy
with the classical isoperimetric inequality, which bounds the area
enclosed by a plane curve by the square of its length (divided by
$4\pi$, though that detail is not important here).

Returning to algebra, we will now explain how to solve the word
problem in $G_1$ using only the relation $h t h^{-1} t^{-2} =
1$. Thanks to the equations $h t^{\pm1} = t^{\pm2} h$ and
$t^{\pm1} h^{-1} = h^{-1} t^{\pm2}$, one can, in any word, move all
positive powers of $h$ to the right of the word and all negative
powers to the left. In other words, any word $W$ is equivalent in
$G_1$ to a word of the form $h^{-m} t^n h^p$ with $m, p \ge 0$. Such a
word represents the transformation $x \mapsto 2^{p - m} x + 2^{-m} n$,
which is the identity if and only if $n = 0$ and $p = m$, that is, if
the word is empty. Therefore, $W = 1$ in $G_1$ if and only if the word
$h^{-m} t^n h^p$ associated to $W$ is the empty word: the word problem
is solved.

This reasoning actually shows that all relations satisfied by $h$ and
$t$ can be formally deduced from the relation $h t h^{-1} t^{-2} =
1$. We say that $G_1$ is presented by the generators $h$ and $t$
subject to the relation $h t h^{-1} t^{-2} = 1$.

In general, we say that
$G = \langle g_1, \dots, g_k \mid r_1, \dots, r_\ell \rangle$, where
the $r_j$ are words in the $g_i$, is a presentation of $G$ if $G$ is
generated by elements $g_i$ satisfying the relations $r_j = 1$, and if
every relation among the $g_i$ can be formally deduced from the
relations $r_j = 1$ (more precisely, $G$ is isomorphic to the quotient
of the free group $F(g_1, \dots, g_k)$ by the subgroup generated by
all products of conjugates of the $r_j$ and their inverses).

Fix an integer $m$, and now ask a machine to prove the relation
$[h^m t h^{-m}, t] = 1$ from $h t h^{-1} t^{-2} = 1$. This is easy for
us, since we can see that $h^m t h^{-m} = t^{2^m}$. But for the
machine, the number of operations will be on the order of $2^m$, that
is, an exponential function of the length of $[h^m t h^{-m}, t]$
(equal to $4m + 4$). Since the words $[h^m t h^{-m}, t]$ are
representative of the general case, $G_1$ satisfies an exponential
isoperimetric inequality.


\end{document}