\documentclass{amsart}
\usepackage[utf8]{inputenc}
    
% \usepackage{wrapfig}

\usepackage{titlesec}
\titleformat{\section}{\normalfont\bf\large}{}{0em}{}
\titleformat{\subsection}{\normalfont\bf}{}{0em}{}

\usepackage{manyfoot}
\DeclareNewFootnote{A}
\DeclareNewFootnote{E}[alph]

\usepackage{xcolor}
\long\def\gray#1{{\color{gray}{#1}}}\let\grey=\gray
\long\def\blue#1{{\color{blue}{#1}}}
\long\def\red#1{{\color{red}{#1}}}

\usepackage{lpic}

% \usepackage{url}
\usepackage[hyperfootnotes=false,
    colorlinks,
    linkcolor={blue!80!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}]{hyperref}

\def\foothref#1#2{\href{#1}{ #2}\footnoteA{\url{#1}}}

% \newcommand{\skipthis}[2][\dots]{\red{[#1]}}
\newcommand{\skipthis}[2][\dots]{\red{[#1]}\gray{#2}}
\newtheorem*{theorem}{Theorem}



\begin{document}
\centerline{\bf\large Charting the Worlds II%
  \footnoteE{English translation of \textit{Representer des Mondes II}, by
    \'Etienne Ghys, (2010),\\
    \url{https://images-archive.math.cnrs.fr/Representer-les-mondes-II.html}.\\
    Translation by Rostislav Matveev.}}%
  \centerline{\bf The networks} \medskip
  \centerline{by \'Etienne Ghys}

\begin{center}
  \includegraphics[width=0.5\textwidth]{Pix/02homunc}
\end{center}

\textbf{``We live in a networked world.''} --- this is a comment we
hear more and more often.

\medskip

Facebook, Twitter, and the Internet in general are obvious examples,
but there are many others:
\begin{itemize}
\item
  The \textit{human brain} contains billions of neurons connected
  to each other by axons.
\item
  A \textit{modern microchip} can contain roughly a billion of transistors
  interconnected in a highly complex pattern.
\item%
  A major part of physics is devoted to studying systems composed of
  vast numbers of interacting particles — for example, the molecules
  that make up the atmosphere.
\item%
  One can also think of \textit{ecological, social, human, and
    commercial networks} --- not to mention telephone networks, etc.
\end{itemize}

A major challenge in contemporary mathematics is to ``map'' these new
virtual worlds --- to produce visual representations that help us
understand how they function. This is not easy, since these are truly
enormous structures, sometimes containing billions of elements, which
certainly cannot be drawn on a sheet of paper like a subway map.

This article raises more questions than it answers. I would first like
to show a few examples, and then discuss a theorem that gives reason
for optimism: \textit{it may be possible to represent these immense networks
in a reasonable way.}

\section{The Brain}

The brain is a mystery. It was toward the end of the nineteenth
century that the neuronal dogma was accepted.%
\skipthis[Broken link]{%
  \footnoteA{The discovery of the neuron.
    \url{http://scienceblogs.com/neurophilosophy/2007/07/%
      the_discovery_of_the_neuron.php}}} %
The brain is not a continuous tissue but a network containing
roughly ten billion neurons connected to each other by axons. Each
neuron is connected to many other neurons --- typically about ten
thousand. How can we picture such a structure? Below is one of the
earliest sketches, dating from 1888:
\begin{center}
  \begin{lpic}[draft,b(15mm),clean]{Pix/cajal-chick-cerebellum(0.5)}
    \lbl[t]{68,-5;\parbox{0.7\textwidth}{\small\centerline{Cajal 1888}
        \url{http://scienceblogs.com/
          neurophilosophy/2007/07/the_discovery_of_the_neuron.php}}}
  \end{lpic}
\end{center}

One of the first “cartographers” of the brain was Wilder Penfield.%
\skipthis[Broken link]{%
\footnoteA{Wilder Penfield, Neural cartographer;
  \url{http://scienceblogs.com/
    neurophilosophy/2008/08/wilder_penfield_neural_cartographer.php.}}} %
In the 1930s, during brain surgeries, he stimulated certain areas of
the brain with electrodes and recorded the patient’s reactions. The
photograph below, taken in 1937, shows a series of numbered tags
marking the locations of the electrodes.

\begin{center}
  \hfill
  \begin{lpic}[b(10mm),draft,clean]{Pix/numered_tickets(0.3)}
    \lbl[t]{60,-5;\parbox{0.4\textwidth}{\small\sf The photograph of tags marking
        the location of electrodes.}}
  \end{lpic}
  \hfill\hfill
  \begin{lpic}[b(10mm),draft,clean]{Pix/02homunc(0.3)}
    \lbl[t]{75,-5;\parbox{0.4\textwidth}{\small\sf\centerline{The homunculus.}}}
  \end{lpic}
  \hfill
  \rule{0mm}{1mm}
  \end{center}
Each number corresponded to a reaction. For example, number 14
produced a tickling sensation from the knee down to the left
foot. Number 5 produced numbness on the right side of the tongue, and
so on. 


This was the beginning of the \textit{homunculus theory}, which sought
to establish a map of the brain corresponding to regions of the body.
The picture on the right is of the famous \textit{homunculus}: the
``map of the brain'', where particular parts of the brain correspond
to parts of the body.

It is a kind of map $f:X\to Y$, where the domain is the brain and the
target is the human body. But how much credence should we give to such
a ``map''? Penfield was exploring completely uncharted territory!  At
the very least, one might be surprised not to see any sexual organs
represented!%
\footnoteA{See, however, the article by Damien Mascret,
  \textit{L’homunculus retrouve son pénis. (The Homunculus Regains His
    Penis.)} Le Généraliste \textnumero{} 2340, 09.09.2005.} %
 
Today, this theory has lost any scientific pretension. Penfield
himself readily admitted this toward the end of his life, writing:
``The figurines [\,\dots] have the defects, and the virtues, of cartoons
in that they are inaccurate anatomically. [\,\dots] They are aids to
memory, no more.''%
\footnoteA{Penfield, Wilder, and Herbert Jasper. \textit{Epilepsy and
    the functional anatomy of the human brain.} (1954),
  pp. 105-106.} %
Wilder Penfield is regarded as one of the pioneers of modern neurosurgery.

Thanks to advances in medical imaging, it is now possible to map the
brain in great detail --- see, for instance, a modern brain
\foothref{http://www.med.harvard.edu/AANLIB/home.html}{atlas.}
Yet it goes without saying that the fundamental problem remains, since
these images, however precise, do not capture the connectivity or the
functioning of the neural network.

\section{Internet}

Nowadays, the number of web pages in the world is around ten billion ---
roughly the same order of magnitude as the number of neurons in a
human brain. However, an average web page is linked to only about
twenty others, which means that the Internet is less ``connected'' than
a brain. On the other hand, the electrical or chemical impulses that
travel through axons are much slower than Internet communications.

How can we get an idea of the structure of such a gigantic network?
Below are the images produced in 1998 and 2005, reminiscent of the
sketch of the neural network from 1888 that we saw earlier.
In this drawings, the points represent web pages, and the lines connect
pages that reference each other through hyperlinks.

\begin{center}
  \hfill
  \begin{lpic}[b(10mm),draft,clean]{Pix/internet_map_1_full(1.1)}
    \lbl[t]{25,-1.5;\parbox{0.4\textwidth}{\small\sf\centerline{The
          image of internet from 1998.}}}
  \end{lpic}
  \hfill
  \begin{lpic}[b(10mm),draft,clean]{Pix/Internet2005(0.3)}
    \lbl[t]{75,-5;\parbox{0.4\textwidth}{\small\sf{The
          image computed in 2005, from the Opte Project}}}
  \end{lpic}
  \hfill
  \rule{0mm}{1mm}
\end{center}

Just as with a detailed image of the brain, these pictures don’t help
much when it comes to understanding the global functioning of the
system. In essence, they are analogous to how one sees the brain under a
microscope.

The first ``web explorers'' proposed around the year 2000 an approximate
map called the ``Bow Tie'':%
\footnoteA{Broder, Andrei, Ravi Kumar, Farzin Maghoul, Prabhakar
  Raghavan, Sridhar Rajagopalan, Raymie Stata, Andrew Tomkins, and
  Janet Wiener. \textit{Graph structure in the web.} Computer networks
  33, no. 1-6 (2000): 309-320.
  \url{https://www.sciencedirect.com/science/article/abs/pii/S1389128600000839}}
\begin{center}
   \includegraphics[width=0.5\textwidth]{Pix/bowtie1}
\end{center}

This map remains relevant even though the numbers have changed. While
one should not expect great precision, it does tell us something about
the structure of the Web, it can be divided into four main regions,
roughly of equal size:
\begin{itemize}
\item The \textbf{S}trongly \textbf{C}onnected \textbf{C}ore,
  consisting of a block of pages that are highly interconnected. This
  is the part where connections are fully active --- in every
  direction.

\item The \textbf{OUT} zone, made up of pages that are heavily cited by the
  core but that, in turn, cite very few others. These are, in a sense,
  the pages that everyone is interested in, but that are interested in
  no one.

\item The \textbf{IN} zone, consisting of pages that cite the core
  frequently but are rarely cited themselves. These are the pages that
  are interested in everything but that interest no one.

\item The \textbf{Disconnected zone}, made up of pages that are not, or are
  only slightly, connected to the main core --- for example, small
  communities with very specific interests that seek no external
  contact.
\end{itemize}
Even though it is simplistic, still this ``map'' is meaningful.
How can we go further?

There is a vast and rapidly growing body of literature on this
subject, attracting the interest of computer scientists, physicists,
mathematicians, as well as psychologists and sociologists.

Faced with a structure we do not yet fully understand --- and which
nevertheless plays an increasingly important role in our society ---
it is fascinating to ask how we imagine the
Web. \foothref{https://cheswick.com/ches/map/}{The Internet Mapping
  Project} invited many people to draw their personal vision of the
Web and to indicate their own position within it. The result is about
a hundred highly instructive sketches.

Here are a few of them:
\begin{center}
  \includegraphics[width=0.33\textwidth]{Pix/image_19-2}%
  \includegraphics[width=0.33\textwidth]{Pix/image_18-2}%
  \includegraphics[width=0.33\textwidth]{Pix/image_15-2-70724}
\end{center}
\begin{center}
  \includegraphics[width=0.33\textwidth]{Pix/image_14-2-622a1}%
  \includegraphics[width=0.33\textwidth]{Pix/image_13-2-31765}%
  \includegraphics[width=0.33\textwidth]{Pix/image_12-2-7c8a8}
\end{center}
\begin{center}
  \includegraphics[width=0.33\textwidth]{Pix/image_10-2-ece6d} %
  \includegraphics[width=0.33\textwidth]{Pix/image_9-2-a0fdc}%
\end{center}

The website \foothref{https://internetgeography.blogspot.com/}{Internet
  Geography: A Collection of Ways to Visually Organize and Explore the
  Internet} is well worth a visit.

\section{The Sciences}

The various sciences, of course, interact. But how is the network of sciences structured?

As in our previous examples, the first “explorers” had to make do with
basic and simple facts. In his \textit{Cours de philosophie positive}%
\footnoteE{English translation by Harriet Martineau is titled
  \textit{The Positive Philosophy of Auguste Comte}. (Ed.)} %
(published between 1830 and 1842), Auguste Comte arranged the sciences
from the most general to the most particular, from the most abstract
to the most concrete: mathematics, astronomy, physics, chemistry,
biology, sociology.
Naturally, at the very top of Comte’s pyramid stood... mathematics!

Today, the interactions between disciplines are more complex than
ever. Many scientists are interested in mapping the relations between
different branches of the sciences.  Below is a map of the scientific
world, taken from %
\foothref{http://www.eigenfactor.org/projects/mappingScience/}{Ranking
  and Mapping Scientific Knowledge.}
\begin{figure}
\begin{center}
  \includegraphics[width=0.5\textwidth]{Pix/Sci2004}
\end{center}
\end{figure}

The mathematician may perhaps regret no longer occupying the top of the pyramid.

\subsection{What is the meaning of such a map?}

Here is the method used --- highly debatable, of course --- but can we
really do better?

The starting point is a database that lists a large number of
scientific journals (around $7\,000$), and that makes it possible, in
particular, to count how many articles, published in one journal, cite,
in their bibliographies, articles from another. The database contains
about $60\,000\,000$ citations from the past decade.

We can view this data as a large table with $7\,000$ rows and $7\,000$
columns. In the $i^{\text{th}}$ row and $j^{\text{th}}$ column, we
record the number $N(i,j)$ of articles published by journal $i$ that
are cited in articles published in journal $j$. Alternatively, we can
think of each journal $i$ as a vector in a $7\,000$-dimensional space,
whose coordinates are $\big(N(i,1),N(i,2),\dots,N(i,7000)\big)$.

The first idea is to take two journals, $i$ and $j$. They are
considered to be thematically close if the angle between their
corresponding vectors is small. Indeed, if two vectors point in almost
the same direction, it means they assign similar relative importance
to all other journals --- in other words, they are interested in roughly the
same topics.

\skipthis[removed par]{ If you remember the dot product of two
  vectors, you know that one can easily compute the angle between two
  vectors from their coordinates. The same idea applies whether we are
  in two or three dimensions — or in 7,000!  High-dimensional geometry
  should not frighten us. In any case, it is reasonable to accept
  that, one way or another, we can estimate “distances” between
  journals.  }%
Next comes a clustering operation --- that is, grouping together
journals that are very close to one another. There are many ways to do
this, and they do not all yield the same result.

Once we have formed the clusters --- the groups of journals --- we
interpret each cluster as representing a ``science.'' To determine the
name of each science automatically, the computer selects a keyword
that appears frequently in the titles of the journals within the
cluster. In this particular study, the computer identified 88
``sciences.''

Once these ``sciences'' are identified, we proceed as if all
journals within the same group formed a single entity. We can then
count the citations between sciences, yielding a new table with only
88 rows and 88 columns. By computing the angles between the
corresponding vectors, we can determine a ``distance'' between two
sciences.

Finally, the goal is to represent these 88 sciences as 88 points in
the plane, in such a way that the distances between them correspond as
closely as possible to the computed angles. This can be done, for
example, by a minimization method such as those described in the
previous article%
\footnoteE{\href{https://images-des-maths.pages.math.cnrs.fr/freeze/Representer-les-mondes.html}
  {Repr\'esenter les Mondes} by \'Etienne Ghys,\\
  \url{https://images-des-maths.pages.math.cnrs.fr/freeze/Representer-les-mondes.html}.
  English translation: \href{URL}{Mapping the Worlds I}, \red{URL}\url{???}} %
--- though, again, many other approaches could be used.  The result is
the map shown above.%
\footnoteE{The thickness of the graph edges indicates citation traffic
  between the ``sciences'', with only significant links shown. See the
  original publication for more detailed explanation. (Ed.)}

I leave it to the reader to judge the interest and relevance of such
constructions. But let us not forget the lessons of Penfield’s
homunculus or the Web’s bow tie: sometimes, simple ideas can produce
good images that are far better than having none at all. However we
should not forget certain scientific errors of the past --- such as
phrenology, which claimed that the bumps on a human skull revealed
character traits.

Many articles are currently being published on this type of question,
each proposing its own methods --- often debatable ones.

Mapping the scientific world, the Internet, or the brain is certainly
not an easy task.  Nevertheless, in at least two significant cases ---
the Internet and the world of science --- we are able to draw on a
sheet of paper a sketch that shows, in broad strokes, how the parts of
such a network communicate with one another.

I would now like to state a theorem that highlights a regularity
property common to all networks, regardless of their size --- one that
allows us to hope for a ``reasonable'' representation.

\section{Networks and Graphs}

Mathematically speaking, the networks that concern us here are called
graphs. A graph consists of a set of objects called vertices (or
nodes), which, depending on the context, may represent neurons, web
pages, scientific journals, or any other entities.  Most importantly,
two vertices can be connected by an edge, which symbolizes ---
depending on the situation --- a neural connection, a hyperlink
between two web pages, a citation from one journal to another, or a
``friendship'' link on Facebook, and so on.

When the number of vertices and edges is small, we can easily draw
such a graph on a sheet of paper.%
\footnoteE{Even relatively small graphs, e.g. with five vertices, may
  not fit on a paper in an embedded way, that is, some edges may have to
  intersect in their interiors. (Ed.)} %
For example, here is a graph with 6 vertices and 7 edges:
\begin{center}
\includegraphics[width=0.3\textwidth]{Pix/graphe-2-72924}  
\end{center}

Graph theory is a fairly old branch of mathematics, but in recent
years it has faced new challenges. The focus now lies on graphs whose
number of vertices is so big that it defies imagination. Earlier, we saw
some attempts to draw representations of the Web graph, with its
billions of vertices.

The Web graph can be treated as a physical object of study, one that
can be measured experimentally --- for example, assessing the speed at
which information circulates, somewhat like an electrical engineer
might study the flow of electricity through a network.
But the Web graph can also be viewed as a mathematical object.

One of the first questions raised about it concerned its
randomness. Suppose we take a very large number of points --- say, ten
billion --- and, for each pair of points, connect them with an edge at
random, with a probability of 2 out of a billion. We repeat this independently
for every pair of points. In this way, we create a graph with roughly
the same number of vertices and edges as the Web graph.

Here is what the result of such a random construction looks like with 100 points and
a probability of connecting two points equal to $5/100$:
\begin{center}
  \includegraphics[width=0.3\textwidth]{Pix/geo1-d8623}
\end{center}
This is what is known as an Erd\H os–R\'enyi random graph, named after
the mathematicians who developed the theory of such structures
in the late 1950s --- long before the Internet existed, and with
entirely different motivations.

But will such random graph with appropriate number of vertices and
edges resemble the Web graph? Can the connections that arise in the
Web be attributed purely to chance? The answer is no. The Web graph is
constructed according to another kind of randomness, that is its own,
and one that we are only beginning to model accurately.

Let us now set these developments aside and turn to Szemer\'edi’s
theorem. For further information about the Web graph (at an
undergraduate level), I recommend Bonato’s book.%
\footnoteA{Bonato, Anthony. \textit{A course on the web graph.}
  Vol. 89. American Mathematical Soc., 2008.}

\section{Szemer\'edi’s Theorem}

This theorem was proven in the 1970s --- again, with motivations quite
different from those we have in mind here.%
\footnoteA{A recurring theme in the development of mathematics: the
  same idea can be useful multiple times, often in unexpected
  ways.}

We wish to say something meaningful about a graph that has a very
large number of vertices --- too large for us to consider them all
individually. In fact, the graphs we have in mind are so vast that
it’s not even clear they are well-defined objects. And even if they
were, they are not static: for example, new connections appear and disappear
constantly on the Web, and our neurons, unfortunately, slowly
degrade and deactivate over time...

So we find ourselves in a situation where the object we wish to
describe is only approximately defined and largely inaccessible. We
can therefore hope for no more than an approximate understanding,
say, within 1\%.

Let $G$ denote an arbitrary graph, and let me try to explain what it
could mean to have a ``reasonably sized understanding to within 1\%.''

Consider two subsets $A$ and $B$ of the vertex set of $G$, which we may
imagine to be disjoint. We want to study how $A$ and $B$ are connected.

Let $X\subset A$ and $Y\subset B$. We count the number of edges
connecting a vertex in $X$ to a vertex in $Y$, and denote this number
by $N(X,Y)$. If $N(X)$ and $N(Y)$ are the numbers of vertices in $X$
and $Y$, respectively, we can think of the ratio
\[
  \frac{N(X,Y)}{N(X)\cdot N(Y)}
\]
as representing the connection probability between $X$ and $Y$.

A priori, this probability depends on the specific choice of $X$ and
$Y$. We shall say that $A$ and $B$ are \textit{well connected} (to
within 1\%) if this probability does not depend too much on the choice
of subsets $X\subset A$ and $Y\subset B$.%
\footnoteE{Well-connectedness essentially says, that the bipartite
  subgraph spanned by the sets of vertices $A$ and $B$ has no easily
  detectable structure and it looks like a typical random graph at a
  first glance.}

More precisely, we require that there exists a number
$p_{A,B}\in[0,1]$ such that, for all  $X\subset A$ and $Y\subset B$
one has
\[
  0.99p_{A,B}
  \leq
  \frac{N(X,Y)}{N(X)\cdot N(Y)}
  \leq
  1.01p_{A,B}
\]

\skipthis[Removed par]{ Readers should not be intimidated by
this formula --- it simply means that $\frac{N(X,Y)}{N(X)\cdot N(Y)}$
and $p_{A,B}$ are equal to within 1\%.}

However, this definition doesn’t quite work. If $X$ and $Y$ each
contain only one vertex, then the ratio
$\frac{N(X,Y)}{N(X)\cdot N(Y)}$ is either $0$ or $1$, which can hardly
be close to $p_{A,B}$.

So, we refine the definition: the inequality above should hold only
when $X$ and $Y$ are large enough --- say, when each contains at least
1\% of the vertices of $A$ and $B$, respectively.

That gives us a definition of what it means for $A$ and $B$ to be
``well connected (within 1\%).'' 

\begin{center}
  \includegraphics[width=0.3\textwidth]{Pix/graphepart-4a3f6.png}
\end{center}
\medskip

Here is an example where $A$ and $B$ are not well connected. You can
see that $X_{1},X_{2}$ and $Y_{1},Y_{2}$ each contain half of the
vertices of $A$ and $B$, respectively. But there are no connections
between $X_{2}$ and $Y_{2}$, while there are many between $X_{1}$ and
$Y_{1}$. For $A$ and $B$ to be well connected, there should be roughly
the same number of connections in both cases.



We will need yet another definition.  We say that we have a partition
of a graph when we have divided its vertex set into subsets
$A_{1},A_{2},\dots,A_{n},$ such that every vertex of the graph belongs
to exactly one of them.

\begin{center}
  \includegraphics[width=0.3\textwidth]{Pix/partition-88053.png}
\end{center}
\medskip

We encountered such a partition earlier when grouping scientific
journals into ``clusters'' that we called ``sciences.'' An example of
a partition of a graph into 5 parts containing 2, 5, 4, 4, and 2
vertices each is pictured above.

A partition is called an equipartition if each $A_{i}$ contains the
same number of vertices. Of course, if we want an equipartition of a
graph $G$ into $n$ parts, then $n$ must divide the total number $N(G)$
vertices.  In our enormous graphs, it’s completely unrealistic to expect
that $N(G)$ will be divisible by 3 or 157!

So we relax the condition slightly.
We say that the $n$ parts $A_{i}$ form an almost-equipartition if the
number of vertices in each $A_{i}$ differs from $N(G)/n$ by at most 1:
\[
  \left| N(A_{i}) - \frac{N(G)}{n} \right| \leq 1
\]

Naturally, the smaller the number $n$ of parts, the more useful the
partition is --- at least compared to the astronomical number of
vertices in the original graph (which we can barely imagine!). So
let’s take a reasonable number, say, $n=1000$.

We are looking for almost-equipartitions that are well connected ---
meaning that the parts $A_{i}$ and $A_{j}$ well connected. All of
them?  No, that would be too much to ask. ``Almost all'' will suffice.
We require that among the $n^{2}=1\,000\,000$ possible pairs
$(i,j)$,
at least $0.99n^{2}$
(that is, $990\,000$)
of them are well
connected.%
\footnoteE{Stricktly speaking, well-connectedness was only defined for
  pairs of disjoint subsets of vertices. We should imagine, that the
  pairs $(A_{i},A_{i})$ are among those that we allow to be ``bad''. (Ed.) }


\subsection{Szemer\'edi’s Theorem (informal statement)}

Now we can state the theorem — but first, a warning: the following
statement may not be exactly correct! We’ll need to refine it.

\begin{theorem}[Szemerédi]
  For any graph, no matter how large, it is always possible to find an
  almost-equipartition into $1000$ parts that are well connected.
\end{theorem}

\blue{\subsection{Szemer\'edi’s Theorem%
\protect\footnoteE{This section was added by the
  editor/translator. (Ed.)}}
}
\blue{
There are several versions of Szemer\'edi's Theorem, which is also
known in the literature as Szemer\'edi's Regularity Lemma. One of the
statements is given below. To make it simpler we first introduce
another definition. 
For a fixed precision level $\epsilon>0$
the \textit{$\epsilon$-regular partition} of a graph $G$ is a
partition of the vertex set of $G$ into $k$ parts
$(A_{1},\dots,A_{k})$, such that among the pairs of distinct $A_{i}$'s
there are at most $\epsilon k^{2}$ ``bad'' pairs, about which we can not
say anything. The rest of the pairs of distinct $A_{i}$'s are
$\epsilon$-well-connected. One may or may not require the partition
to be an almost equipartition. The theorem holds in both setups,
however the known bounds on the size of the partition will be
different.
}
\blue{
Now we are ready to state the theorem.  For any precision level
$\epsilon$ ($1\%$ in the text above) the theorem provides the upper
bound $M$ on the size of the $\epsilon$-regular partition, for any
sufficiently large graph.
\begin{theorem}[Szemer\'edi's Regularity Lemma]
  For any $\epsilon>0$ (precision level) there exist $M>0$ (maximal
  number of parts) such that for every graph $G$ with at least $M$
  vertices there exist an $\epsilon$-regular
  partition of $G$ with the number of parts not exceeding $M$.
\end{theorem}
}

\blue{ The known bounds on $M$ are just astounding,%
  \footnoteE{W.T. Gowers, \textit{Quasirandomness, counting and
      regularity for 3-uniform hypergraphs},
    Combin. Probab. Comput. 15 (2006), 143–184.} %
  they are in the form of exponential towers (repeated exponentiation)
  of the height proportional to $\epsilon^{-2}$.  There is no saying,
  how large this number for $\epsilon=0.01$ is, there is nothing in
  the world to compare it to. It has also been shown that there are
  families of graphs for which the required number of parts is indeed
  about that big, so that the bound can not be improved by much. We
  may still hope that such synthetic examples are rare and there are
  large classes of graphs for which Szemer\'edi Regularity Lemma with
  some reasonable $M$ holds.}

\section{The Significance of the Theorem and a Few Comments}

Once a well-connected, almost-equipartition is known, we can draw a
``reasonable'' representation of the graph we are studying.

We imagine drawing $1\,000$ points on a plane, each representing one
of the $A_{i}$, which we can think of as a ``cluster,'' a ``science,''
or perhaps an ``organ'' of the network --- each labeled with its
corresponding number $i$.  Then, along the segment joining the points
$i$ and $j$, we write the number $P_{A_{i}A_{j}}$.

This simple diagram serves as a genuine map of the graph to within $1\%$
accuracy! And this remains true even if the original graph contains
billions upon billions of vertices. Of course, such a map does not
allow us to reconstruct the entire graph --- but it does tell us, to
within $1\%$, the number of connections between any two sufficiently
large parts $X$ and $Y$. It suffices to know how $X$ and $Y$ intersect the
``clusters'' $A_{i}$

In short, anyone interested in the global functioning of the graph can
be quite satisfied with such a map. If we wish, we can even position
the $1\,000$ points on the plane in such a way that the distances between
them reflect, as closely as possible, the degree of connectivity: the
larger $p_{A_{i}A_{j}}$ is, the closer the corresponding points will
appear.

\subsection{Two caveats (that somewhat spoil the theorem’s magic)}

I have saved two comments for the end because they somewhat diminish
the theorem’s appeal --- though they certainly do not destroy the desire
to improve it, and to overcome the two shortcomings I will now
highlight.

First, the theorem as stated above is not quite
correct. Unfortunately, I cannot guarantee a partition with exactly
$1\,000$ clusters, as I somewhat boldly claimed earlier. The truth is
that for each desired precision (say, $1\%$ in our example), there
exists some integer $n$ that makes the theorem valid.

What is the actual value of $n$ for a $1\%$ precision? Is it $1\,000$, as
I suggested? I have no idea. All I know is that such an integer $n$
exists. The important point is that this $n$ depends only on the chosen
precision --- not on the size of the graph itself. If it depended on the
size, the theorem would lose all appeal.

I would not be surprised if the reader felt frustrated by such a
statement --- ``an integer $n$ exists, but we don’t know it.'' That’s how
mathematics often is: we do what we can!

Now, the hunt is on to determine the best possible $n$ for a given
precision. \skipthis[Removed sentences. The result of Gowers says that
$M$ is an exponential tower of height $1/\epsilon^{2}$]{Recent work by
  T. Gowers suggests that $n$ grows roughly like the inverse square of
  the desired precision. That is not very satisfying: for a precision
  of $1\%$ (that is, $0.01$), this would give $n=10\,000$.}
Researchers are striving to make the theorem effective --- to obtain
actual, reasonable values of $n$ for realistic levels of precision
\blue{at least for some large classes of graphs or a slightly modified
conditions imposed on the partition}.\skipthis[Removed sentence. See blue
sentences above]{To
achieve this, they might slightly adjust the conditions imposed on the
partition.} The theorem is flexible, and the goal is to make it usable.

\subsection{Finding the partition itself}

Along similar lines, it is not enough to assert that there exists a
partition with, say, $1\,000$ clusters. We must also be able to find it
if we wish to draw a map!

This, too, is an area of active research: developing efficient (and
not overly time-consuming) computational methods to actually find
Szemer\'edi’s clusters.

Readers with a solid mathematical background may enjoy reading an
engaging preprint on \href{https://arxiv.org/pdf/0902.0132}{``Very
  Large Graphs''},%
\footnoteA{Lov\'asz, L\'aszl\'o. \textit{Very large graphs.} In
  Current developments in mathematics, 2008, vol. 2008,
  pp. 67-129. International Press of Boston,
  2009. \url{https://arxiv.org/pdf/0902.0132}} %
which delves deeper into these questions.

\section{Other Networks...}

To conclude, here is another network we would like to understand
better. It is a graph describing $3\,200$ interactions among $1\,700$ human
proteins --- a work that earned its authors a scientific award in 2005.

This graph is rather complicated! One would certainly like to apply
Szemer\'edi’s theorem to it\dots
\begin{center}
  \includegraphics[]{Pix/Proteine-df7a8.jpg}
\end{center}

\end{document}